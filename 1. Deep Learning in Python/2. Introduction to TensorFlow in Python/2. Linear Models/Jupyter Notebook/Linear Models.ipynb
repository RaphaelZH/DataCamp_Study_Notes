{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Input-data\" data-toc-modified-id=\"Input-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Input data</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Importing-data-for-use-in-TensorFlow\" data-toc-modified-id=\"[note-1]-Importing-data-for-use-in-TensorFlow-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>[note-1]</code> Importing data for use in TensorFlow</a></span></li><li><span><a href=\"#[code-1]-How-to-import-and-convert-data\" data-toc-modified-id=\"[code-1]-How-to-import-and-convert-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>[code-1]</code> How to import and convert data</a></span></li><li><span><a href=\"#[note-2]-Parameters-of-read_csv()\" data-toc-modified-id=\"[note-2]-Parameters-of-read_csv()-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>[note-2]</code> Parameters of <code>read_csv()</code></a></span></li><li><span><a href=\"#[note-3]-Using-mixed-type-datasets\" data-toc-modified-id=\"[note-3]-Using-mixed-type-datasets-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>[note-3]</code> Using mixed type datasets</a></span></li><li><span><a href=\"#[code-2]-Setting-the-data-type\" data-toc-modified-id=\"[code-2]-Setting-the-data-type-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><code>[code-2]</code> Setting the data type</a></span></li><li><span><a href=\"#[task-1]-Load-data-using-pandas\" data-toc-modified-id=\"[task-1]-Load-data-using-pandas-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span><code>[task-1]</code> Load data using pandas</a></span></li><li><span><a href=\"#[task-2]-Setting-the-data-type\" data-toc-modified-id=\"[task-2]-Setting-the-data-type-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span><code>[task-2]</code> Setting the data type</a></span></li></ul></li><li><span><a href=\"#Loss-functions\" data-toc-modified-id=\"Loss-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loss functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Introduction-to-loss-functions\" data-toc-modified-id=\"[note-1]-Introduction-to-loss-functions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><code>[note-1]</code> Introduction to loss functions</a></span></li><li><span><a href=\"#[note-2]-Common-loss-functions-in-TensorFlow\" data-toc-modified-id=\"[note-2]-Common-loss-functions-in-TensorFlow-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><code>[note-2]</code> Common loss functions in TensorFlow</a></span></li><li><span><a href=\"#[note-3]-Why-is-it-in-need-to-care-about-loss-functions?\" data-toc-modified-id=\"[note-3]-Why-is-it-in-need-to-care-about-loss-functions?-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><code>[note-3]</code> Why is it in need to care about loss functions?</a></span></li><li><span><a href=\"#[code-1]-Defining-a-loss-function\" data-toc-modified-id=\"[code-1]-Defining-a-loss-function-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span><code>[code-1]</code> Defining a loss function</a></span></li><li><span><a href=\"#[task-1]-Loss-functions-in-TensorFlow\" data-toc-modified-id=\"[task-1]-Loss-functions-in-TensorFlow-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span><code>[task-1]</code> Loss functions in TensorFlow</a></span></li><li><span><a href=\"#[task-2]-Modifying-the-loss-function\" data-toc-modified-id=\"[task-2]-Modifying-the-loss-function-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span><code>[task-2]</code> Modifying the loss function</a></span></li></ul></li><li><span><a href=\"#Linear-regression\" data-toc-modified-id=\"Linear-regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Linear regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-What-is-linear-regression?\" data-toc-modified-id=\"[note-1]-What-is-linear-regression?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>[note-1]</code> What is linear regression?</a></span></li><li><span><a href=\"#[note-2]-The-linear-regression-model\" data-toc-modified-id=\"[note-2]-The-linear-regression-model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><code>[note-2]</code> The linear regression model</a></span></li><li><span><a href=\"#[code-1]-Linear-regression-in-TensorFlow\" data-toc-modified-id=\"[code-1]-Linear-regression-in-TensorFlow-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><code>[code-1]</code> Linear regression in TensorFlow</a></span></li><li><span><a href=\"#[task-1]-Set-up-a-linear-regression\" data-toc-modified-id=\"[task-1]-Set-up-a-linear-regression-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>[task-1]</code> Set up a linear regression</a></span></li></ul></li><li><span><a href=\"#Batch-training\" data-toc-modified-id=\"Batch-training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Batch training</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-batch-training?\" data-toc-modified-id=\"What-is-batch-training?-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>What is batch training?</a></span></li><li><span><a href=\"#What-is-the-chunksize-parameter?\" data-toc-modified-id=\"What-is-the-chunksize-parameter?-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>What is the <code>chunksize</code> parameter?</a></span></li><li><span><a href=\"#Code-of-the-chunksize-parameter:\" data-toc-modified-id=\"Code-of-the-chunksize-parameter:-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Code of the <code>chunksize</code> parameter:</a></span></li><li><span><a href=\"#Code-of-training-a-linear-model-in-batches:\" data-toc-modified-id=\"Code-of-training-a-linear-model-in-batches:-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Code of training a linear model in batches:</a></span></li><li><span><a href=\"#Compare-full-sample-versus-batch-training,-what-are-the-differences?\" data-toc-modified-id=\"Compare-full-sample-versus-batch-training,-what-are-the-differences?-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Compare full sample versus batch training, what are the differences?</a></span></li><li><span><a href=\"#Practice-exercises-for-batch-training:\" data-toc-modified-id=\"Practice-exercises-for-batch-training:-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Practice exercises for batch training:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-1]` Importing data for use in TensorFlow\n",
    "\n",
    "* **Data can be imported using `tensorflow`**:\n",
    "\n",
    "    * useful for managing complex pipelines\n",
    "\n",
    "* **Simpler option**:\n",
    "\n",
    "    * import data using `pandas`\n",
    "    \n",
    "    * convert data to `numpy` array\n",
    "    \n",
    "    * use in `tensorflow` without modification\n",
    "\n",
    "* Pandas also has methods for handling data in other formats:\n",
    "\n",
    "    * e.g. `read_json()` , `read_html()` , `read_excel()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-1]` How to import and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:20:59.254988Z",
     "start_time": "2021-05-15T16:20:51.950089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7129300520 '20141013T000000' 221900.0 ... -122.257 1340 5650]\n",
      " [6414100192 '20141209T000000' 538000.0 ... -122.319 1690 7639]\n",
      " [5631500400 '20150225T000000' 180000.0 ... -122.233 2720 8062]\n",
      " ...\n",
      " [1523300141 '20140623T000000' 402101.0 ... -122.299 1020 2007]\n",
      " [291310100 '20150116T000000' 400000.0 ... -122.069 1410 1287]\n",
      " [1523300157 '20141015T000000' 325000.0 ... -122.299 1020 1357]]\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from csv\n",
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "\n",
    "# Convert to numpy array\n",
    "housing = np.array(housing)\n",
    "\n",
    "print(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Parameters of `read_csv()`\n",
    "\n",
    "![Parameters of read_csv](../Figures/1.%20Parameters%20of%20read_csv.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-3]` Using mixed type datasets\n",
    "\n",
    "![Using mixed type datasets](../Figures/2.%20Using%20mixed%20type%20datasets.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-2]` Setting the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:20:59.317558Z",
     "start_time": "2021-05-15T16:20:59.261043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "# Load KC dataset\n",
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "\n",
    "# Convert price column to float32\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Convert waterfront column to Boolean\n",
    "waterfront = np.array(housing['waterfront'], np.bool)\n",
    "\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:15.228060Z",
     "start_time": "2021-05-15T16:20:59.320869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([221900. 538000. 180000. ... 402101. 400000. 325000.], shape=(21613,), dtype=float32)\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load KC dataset\n",
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "\n",
    "# Convert price column to float32\n",
    "price = tf.cast(housing['price'], tf.float32)\n",
    "\n",
    "# Convert waterfront column to Boolean\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-1]` Load data using pandas\n",
    "\n",
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:15.317171Z",
     "start_time": "2021-05-15T16:21:15.235943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        221900.0\n",
      "1        538000.0\n",
      "2        180000.0\n",
      "3        604000.0\n",
      "4        510000.0\n",
      "           ...   \n",
      "21608    360000.0\n",
      "21609    400000.0\n",
      "21610    402101.0\n",
      "21611    400000.0\n",
      "21612    325000.0\n",
      "Name: price, Length: 21613, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import pandas under the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the path to a string variable named data_path\n",
    "data_path = '../Datasets/1. House sales in King County.csv'\n",
    "\n",
    "# Load the dataset as a dataframe named housing\n",
    "housing = pd.read_csv(data_path)\n",
    "\n",
    "# Print the price column of housing\n",
    "print(housing['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]` Setting the data type\n",
    "\n",
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:15.334944Z",
     "start_time": "2021-05-15T16:21:15.328316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and tensorflow with their standard aliases\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-1]` Introduction to loss functions\n",
    "\n",
    "* **Fundamental `tensorflow` operation**:\n",
    "\n",
    "    * used to train a model\n",
    "    \n",
    "    * the measure of model fit\n",
    "\n",
    "* **Higher value $\\rightarrow$ worse fit**:\n",
    "\n",
    "    * minimize the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Common loss functions in TensorFlow\n",
    "\n",
    "* **TensorFlow has operations for common loss functions**:\n",
    "\n",
    "    * mean squared error (MSE)\n",
    "    \n",
    "    * mean absolute error (MAE)\n",
    "    \n",
    "    * Huber error\n",
    "\n",
    "* **Loss functions are accessible from `tf.keras.losses`**:\n",
    "\n",
    "    * `tf.keras.losses.MSE()`\n",
    "    \n",
    "    * `tf.keras.losses.MAE()`\n",
    "    \n",
    "    * `tf.keras.losses.Huber()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-3]` Why is it in need to care about loss functions?\n",
    "\n",
    "* **MSE**:\n",
    "\n",
    "    * strongly penalizes outliers\n",
    "    \n",
    "    * high (gradient) sensitivity near minimum\n",
    "\n",
    "* **MAE**:\n",
    "\n",
    "    * scales linearly with the size of the error\n",
    "    \n",
    "    * low sensitivity near minimum\n",
    "\n",
    "* **Huber**:\n",
    "\n",
    "    * similar to MSE near minimum\n",
    "    \n",
    "    * similar to MAE away from the minimum\n",
    "\n",
    "![Why is it in need to care about loss functions](../Figures/3.%20Why%20is%20it%20in%20need%20to%20care%20about%20loss%20functions.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-1]` Defining a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:08.162160Z",
     "start_time": "2021-05-15T16:34:08.077349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=145.44653>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "\n",
    "price_log = np.log(np.array(housing['price'], np.float32))\n",
    "size_log = np.log(np.array(housing['sqft_lot'], np.float32))\n",
    "targets = price_log\n",
    "features = size_log\n",
    "intercept = 0.1\n",
    "slope = 0.1\n",
    "\n",
    "predictions = intercept + features * slope\n",
    "\n",
    "# Import TensorFlow under standard alias\n",
    "import tensorflow as tf\n",
    "\n",
    "# Compute the MSE loss\n",
    "loss = tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:08.695725Z",
     "start_time": "2021-05-15T16:34:08.691918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope=slope, features=features):\n",
    "    return intercept + features * slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:09.347483Z",
     "start_time": "2021-05-15T16:34:09.342251Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a loss function to compute the MSE\n",
    "def loss_function(intercept, slope, targets=targets, features=features):\n",
    "    # Compute the predictions for a linear model\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "\n",
    "    # Return the loss\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:09.842321Z",
     "start_time": "2021-05-15T16:34:09.830787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=145.57338>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.3, random_state=42)\n",
    "\n",
    "# Compute the loss for test data inputs\n",
    "loss_function(intercept, slope, test_targets, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:10.934920Z",
     "start_time": "2021-05-15T16:34:10.929150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=145.44653>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the loss for default data inputs\n",
    "loss_function(intercept, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-1]` Loss functions in TensorFlow\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:12.789665Z",
     "start_time": "2021-05-15T16:34:12.786741Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:14.344938Z",
     "start_time": "2021-05-15T16:34:14.217272Z"
    }
   },
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "price = np.array(housing['price'], np.float32)\n",
    "predictions = np.loadtxt(\n",
    "    '../Datasets/2. House sales in King County predictions data.csv',\n",
    "    delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice 1/2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:16.802253Z",
     "start_time": "2021-05-15T16:34:16.798232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141171604777.141\n"
     ]
    }
   ],
   "source": [
    "# Import the keras module from tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Compute the mean squared error (mse)\n",
    "loss = keras.losses.mse(price, predictions)\n",
    "\n",
    "# Print the mean squared error (mse)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice 2/2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:18.009867Z",
     "start_time": "2021-05-15T16:34:17.997333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268827.9930163703\n"
     ]
    }
   ],
   "source": [
    "# Import the keras module from tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Compute the mean absolute error (mae)\n",
    "loss = keras.losses.mae(price, predictions)\n",
    "\n",
    "# Print the mean absolute error (mae)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]` Modifying the loss function\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:18.933072Z",
     "start_time": "2021-05-15T16:34:18.930287Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import constant, Variable, float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:20.100244Z",
     "start_time": "2021-05-15T16:34:20.087974Z"
    }
   },
   "outputs": [],
   "source": [
    "features = constant([1., 2., 3., 4., 5.], dtype=float32)\n",
    "targets = constant([2., 4., 6., 8., 10.], dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:21.152782Z",
     "start_time": "2021-05-15T16:34:21.138118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = Variable(1.0, float32)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features=features):\n",
    "    return scalar * features\n",
    "\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features=features, targets=targets):\n",
    "    # Compute the predicted values\n",
    "    predictions = model(scalar, features)\n",
    "\n",
    "    # Return the mean absolute error loss\n",
    "    return keras.losses.mae(targets, predictions)\n",
    "\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-1]` What is linear regression?\n",
    "\n",
    "![What is linear regression](../Figures/4.%20What%20is%20linear%20regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` The linear regression model\n",
    "\n",
    "* A linear regression model assumes a linear relationship:\n",
    "\n",
    "    * $price = intercept + size \\times slope + error$\n",
    "\n",
    "* This is an example of a univariate regression:\n",
    "\n",
    "    * e.g., there is only one feature: `size`\n",
    "\n",
    "* Multiple regression models have more than one feature.\n",
    "\n",
    "    * e.g., there are two features: `size` and `location`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-1]` Linear regression in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:23.888338Z",
     "start_time": "2021-05-15T16:34:23.817983Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "\n",
    "# Define the targets and features\n",
    "price = np.log(np.array(housing['price'], np.float32))\n",
    "size = np.log(np.array(housing['sqft_lot'], np.float32))\n",
    "\n",
    "# Define the intercept and slope\n",
    "intercept = tf.Variable(0.1, np.float32)\n",
    "slope = tf.Variable(0.1, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:23.897619Z",
     "start_time": "2021-05-15T16:34:23.894123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features=size):\n",
    "    return intercept + features * slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:24.852864Z",
     "start_time": "2021-05-15T16:34:24.848738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the predicted values and loss\n",
    "def loss_function(intercept, slope, targets=price, features=size):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:34:25.080591Z",
     "start_time": "2021-05-15T16:34:25.075495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define an optimization operation\n",
    "opt = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:35:48.901499Z",
     "start_time": "2021-05-15T16:35:46.989736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.8807738, shape=(), dtype=float32)\n",
      "\n",
      "…\n",
      "\n",
      "tf.Tensor(1.4762464, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Minimize the loss function and print the loss\n",
    "for j in range(1000):\n",
    "    opt.minimize(lambda: loss_function(intercept, slope),\n",
    "                 var_list=[intercept, slope])\n",
    "    if j == range(1000)[0]:\n",
    "        print(loss_function(intercept, slope))\n",
    "        print(\"\\n…\\n\")\n",
    "    elif j == range(1000)[-1]:\n",
    "        print(loss_function(intercept, slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:35:49.174100Z",
     "start_time": "2021-05-15T16:35:49.157868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3391368 1.2888577\n"
     ]
    }
   ],
   "source": [
    "# Print the trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-1]` Set up a linear regression\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:21.176726Z",
     "start_time": "2021-05-15T16:21:21.173517Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import add, multiply, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:37:08.308034Z",
     "start_time": "2021-05-15T16:37:08.242662Z"
    }
   },
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../Datasets/1. House sales in King County.csv')\n",
    "price_log = np.log(np.array(housing['price'], np.float32))\n",
    "size_log = np.log(np.array(housing['sqft_lot'], np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:38:15.059315Z",
     "start_time": "2021-05-15T16:38:15.050170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.44653\n",
      "71.866\n"
     ]
    }
   ],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features=size_log):\n",
    "    return add(intercept, multiply(features, slope))\n",
    "\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(intercept, slope, features=size_log, targets=price_log):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "\n",
    "    # Return the mean squared error loss\n",
    "    return keras.losses.mse(targets, predictions)\n",
    "\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1).numpy())\n",
    "print(loss_function(0.1, 0.5).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]`\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.040888Z",
     "start_time": "2021-05-15T16:21:05.427Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.050728Z",
     "start_time": "2021-05-15T16:21:05.928Z"
    }
   },
   "outputs": [],
   "source": [
    "intercept = Variable(5, dtype=np.float32)\n",
    "slope = Variable(0.001, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.065919Z",
     "start_time": "2021-05-15T16:21:06.444Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(intercept, slope):\n",
    "    size_range = np.linspace(6, 14, 100)\n",
    "    price_pred = [intercept + slope * s for s in size_range]\n",
    "    plt.scatter(size_log, price_log, color='black')\n",
    "    plt.plot(size_range, price_pred, linewidth=3.0, color='red')\n",
    "    plt.xlabel('log(size)')\n",
    "    plt.ylabel('log(price)')\n",
    "    plt.title('Scatterplot of data and fitted regression line')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Linear model training practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.075696Z",
     "start_time": "2021-05-15T16:21:06.967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an adam optimizer\n",
    "opt = keras.optimizers.Adam(0.5)\n",
    "\n",
    "for j in range(100):\n",
    "    # Apply minimize, pass the loss function, and supply the variables\n",
    "    opt.minimize(lambda: loss_function(intercept, slope),\n",
    "                 var_list=[intercept, slope])\n",
    "\n",
    "    # Print every 10th value of the loss\n",
    "    if j % 10 == 0:\n",
    "        print(loss_function(intercept, slope).numpy())\n",
    "\n",
    "# Plot data and regression line\n",
    "plot_results(intercept, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:46:08.637519Z",
     "start_time": "2020-12-11T20:46:08.631878Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.079310Z",
     "start_time": "2021-05-15T16:21:07.521Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrooms = np.array(housing['bedrooms'], np.float32)\n",
    "params = Variable([0.1, 0.05, 0.02], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.085865Z",
     "start_time": "2021-05-15T16:21:08.118Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_results(params):\n",
    "    return print(\n",
    "        'loss: {:0.3f}, intercept: {:0.3f}, slope_1: {:0.3f}, slope_2: {:0.3f}'\n",
    "        .format(\n",
    "            loss_function(params).numpy(), params[0].numpy(),\n",
    "            params[1].numpy(), params[2].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Multiple linear regression practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.088388Z",
     "start_time": "2021-05-15T16:21:08.645Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the linear regression model\n",
    "def linear_regression(params, feature1=size_log, feature2=bedrooms):\n",
    "    return params[0] + feature1 * params[1] + feature2 * params[2]\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(params,\n",
    "                  targets=price_log,\n",
    "                  feature1=size_log,\n",
    "                  feature2=bedrooms):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(params, feature1, feature2)\n",
    "\n",
    "    # Use the mean absolute error loss\n",
    "    return keras.losses.mae(targets, predictions)\n",
    "\n",
    "\n",
    "# Define the optimize operation\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "    opt.minimize(lambda: loss_function(params), var_list=[params])\n",
    "    print_results(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is batch training?\n",
    "\n",
    "![What is batch training](ref7.%20What%20is%20batch%20training.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the `chunksize` parameter?\n",
    "\n",
    "* `pandas.read_csv()` allows to load data in batches:\n",
    "\t\n",
    "    * avoid loading entire dataset\n",
    "\t\n",
    "    * `chunksize` parameter provides batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of the `chunksize` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.090622Z",
     "start_time": "2021-05-15T16:21:10.665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('ref1. King county house sales.csv', chunksize=100):\n",
    "    # Extract price column\n",
    "    price = np.array(batch['price'], np.float32)\n",
    "\n",
    "    # Extract size column\n",
    "    size = np.array(batch['sqft_living'], np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of training a linear model in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.092242Z",
     "start_time": "2021-05-15T16:21:11.502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import tensorflow, pandas, and numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.094824Z",
     "start_time": "2021-05-15T16:21:11.539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define trainable variables\n",
    "intercept = tf.Variable(0.1, tf.float32)\n",
    "slope = tf.Variable(0.1, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.096592Z",
     "start_time": "2021-05-15T16:21:11.573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    return intercept + features * slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.098862Z",
     "start_time": "2021-05-15T16:21:11.615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute predicted values and return loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.100955Z",
     "start_time": "2021-05-15T16:21:11.656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define optimization operation\n",
    "opt = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.104479Z",
     "start_time": "2021-05-15T16:21:11.694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data in batches from pandas\n",
    "for batch in pd.read_csv('ref1. King county house sales.csv', chunksize=100):\n",
    "    # Extract the target and feature columns\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "    size_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "    # Minimize the loss function\n",
    "    opt.minimize(\n",
    "        lambda: loss_function(intercept, slope, price_batch, size_batch),\n",
    "        var_list=[intercept, slope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.113246Z",
     "start_time": "2021-05-15T16:21:11.731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print parameter values\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare full sample versus batch training, what are the differences?\n",
    "\n",
    "* Full Sample\n",
    "    \n",
    "    1. One update per epoch\n",
    "    \n",
    "    2. Accepts dataset without modification\n",
    "    \n",
    "    3. Limited by memory\n",
    "\n",
    "* Batch Training\n",
    "    \n",
    "    1. Multiple updates per epoch\n",
    "    \n",
    "    2. Requires the division of dataset\n",
    "    \n",
    "    3. No limit on dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice exercises for batch training:\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.115423Z",
     "start_time": "2021-05-15T16:21:12.924Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import Variable, keras, float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Batch train preparing practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.117386Z",
     "start_time": "2021-05-15T16:21:13.538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = Variable(10.0, float32)\n",
    "slope = Variable(0.5, float32)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    # Define the predicted values\n",
    "    return intercept + features * slope\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    # Define the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "\n",
    "    # Define the MSE loss\n",
    "    return keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.119627Z",
     "start_time": "2021-05-15T16:21:14.096Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Linear model batches training practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T16:21:22.121258Z",
     "start_time": "2021-05-15T16:21:14.717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('ref1. King county house sales.csv', chunksize=100):\n",
    "    size_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "    # Extract the price values for the current batch\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "    # Complete the loss, fill in the variable list, and minimize\n",
    "    opt.minimize(\n",
    "        lambda: loss_function(intercept, slope, price_batch, size_batch),\n",
    "        var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
