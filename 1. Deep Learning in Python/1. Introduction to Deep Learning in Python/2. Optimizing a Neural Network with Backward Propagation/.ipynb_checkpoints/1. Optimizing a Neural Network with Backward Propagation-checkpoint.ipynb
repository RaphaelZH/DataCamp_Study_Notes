{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#The-need-for-optimization\" data-toc-modified-id=\"The-need-for-optimization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>The need for optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-A-baseline-neural-network\" data-toc-modified-id=\"[note-1]-A-baseline-neural-network-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>[note-1]</code> A baseline neural network</a></span></li><li><span><a href=\"#[note-2]-Predictions-with-multiple-points\" data-toc-modified-id=\"[note-2]-Predictions-with-multiple-points-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>[note-2]</code> Predictions with multiple points</a></span></li><li><span><a href=\"#[note-3]-Loss-function\" data-toc-modified-id=\"[note-3]-Loss-function-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>[note-3]</code> Loss function</a></span></li><li><span><a href=\"#[note-4]-Gradient-descent\" data-toc-modified-id=\"[note-4]-Gradient-descent-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>[note-4]</code> Gradient descent</a></span></li><li><span><a href=\"#[note-5]-Gradient-descent-steps\" data-toc-modified-id=\"[note-5]-Gradient-descent-steps-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><code>[note-5]</code> Gradient descent steps</a></span></li><li><span><a href=\"#[note-6]-Optimizing-a-model-with-a-single-weight\" data-toc-modified-id=\"[note-6]-Optimizing-a-model-with-a-single-weight-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span><code>[note-6]</code> Optimizing a model with a single weight</a></span></li><li><span><a href=\"#[quiz-1]-Calculating-model-errors\" data-toc-modified-id=\"[quiz-1]-Calculating-model-errors-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span><code>[quiz-1]</code> Calculating model errors</a></span></li><li><span><a href=\"#[quiz-2]-Understanding-how-weights-change-model-accuracy\" data-toc-modified-id=\"[quiz-2]-Understanding-how-weights-change-model-accuracy-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span><code>[quiz-2]</code> Understanding how weights change model accuracy</a></span></li><li><span><a href=\"#[task-1]-Coding-how-weight-changes-affect-the-accuracy\" data-toc-modified-id=\"[task-1]-Coding-how-weight-changes-affect-the-accuracy-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span><code>[task-1]</code> Coding how weight changes affect the accuracy</a></span></li><li><span><a href=\"#[task-2]-Scaling-up-to-multiple-data-points\" data-toc-modified-id=\"[task-2]-Scaling-up-to-multiple-data-points-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span><code>[task-2]</code> Scaling up to multiple data points</a></span></li></ul></li><li><span><a href=\"#Gradient-descent\" data-toc-modified-id=\"Gradient-descent-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gradient descent</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Gradient-descent\" data-toc-modified-id=\"[note-1]-Gradient-descent-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><code>[note-1]</code> Gradient descent</a></span></li><li><span><a href=\"#[note-2]-Slope-calculation-example\" data-toc-modified-id=\"[note-2]-Slope-calculation-example-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><code>[note-2]</code> Slope calculation example</a></span></li><li><span><a href=\"#[note-3]-Network-with-two-inputs-affecting-prediction\" data-toc-modified-id=\"[note-3]-Network-with-two-inputs-affecting-prediction-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><code>[note-3]</code> Network with two inputs affecting prediction</a></span></li><li><span><a href=\"#[code-1]-Calculate-slopes-and-update-weights\" data-toc-modified-id=\"[code-1]-Calculate-slopes-and-update-weights-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span><code>[code-1]</code> Calculate slopes and update weights</a></span></li><li><span><a href=\"#[task-1]-Calculating-slopes\" data-toc-modified-id=\"[task-1]-Calculating-slopes-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span><code>[task-1]</code> Calculating slopes</a></span></li><li><span><a href=\"#[task-2]-Improving-model-weights\" data-toc-modified-id=\"[task-2]-Improving-model-weights-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span><code>[task-2]</code> Improving model weights</a></span></li></ul></li><li><span><a href=\"#Backpropagation\" data-toc-modified-id=\"Backpropagation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Backpropagation</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Backpropagation\" data-toc-modified-id=\"[note-1]-Backpropagation-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>[note-1]</code> Backpropagation</a></span></li><li><span><a href=\"#[note-2]-Backpropagation-process\" data-toc-modified-id=\"[note-2]-Backpropagation-process-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><code>[note-2]</code> Backpropagation process</a></span></li><li><span><a href=\"#[quiz-1]-The-relationship-between-the-forward-and-the-backward-propagation\" data-toc-modified-id=\"[quiz-1]-The-relationship-between-the-forward-and-the-backward-propagation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><code>[quiz-1]</code> The relationship between the forward and the backward propagation</a></span></li><li><span><a href=\"#[quiz-2]-Thinking-about-backward-propagation\" data-toc-modified-id=\"[quiz-2]-Thinking-about-backward-propagation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>[quiz-2]</code> Thinking about backward propagation</a></span></li></ul></li><li><span><a href=\"#Backpropagation-in-practice\" data-toc-modified-id=\"Backpropagation-in-practice-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Backpropagation in practice</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Calculating-slopes-associated-with-any-weight\" data-toc-modified-id=\"[note-1]-Calculating-slopes-associated-with-any-weight-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><code>[note-1]</code> Calculating slopes associated with any weight</a></span></li><li><span><a href=\"#[note-2]-Backpropagation:-Recap\" data-toc-modified-id=\"[note-2]-Backpropagation:-Recap-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span><code>[note-2]</code> Backpropagation: Recap</a></span></li><li><span><a href=\"#What-are-the-principles-of-stochastic-gradient-descent?\" data-toc-modified-id=\"What-are-the-principles-of-stochastic-gradient-descent?-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>What are the principles of stochastic gradient descent?</a></span></li><li><span><a href=\"#Practice-question-for-a-round-of-backpropagation:\" data-toc-modified-id=\"Practice-question-for-a-round-of-backpropagation:-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Practice question for a round of backpropagation:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The need for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` A baseline neural network\n",
    "\n",
    "![A baseline neural network](ref1.%20A%20baseline%20neural%20network.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Predictions with multiple points\n",
    "\n",
    "* Making accurate predictions gets harder with more points.\n",
    "\n",
    "* At any set of weights, there are many values of the error corresponding to the many points that make predictions for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-3]` Loss function\n",
    "\n",
    "* Aggregates errors in predictions from many data points into a single number.\n",
    "\n",
    "* The loss function is a measure of the model's predictive performance.\n",
    "\n",
    "* A lower loss function value means a better model.\n",
    "\n",
    "* Goal: find the weights that give the lowest value for the loss function.\n",
    "\n",
    "* Gradient descent.\n",
    "\n",
    "![Loss function](ref2.%20Loss%20function.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-4]` Gradient descent\n",
    "\n",
    "* Imagine starting in a pitch dark field.\n",
    "\n",
    "* Want to find the lowest point.\n",
    "\n",
    "* Feel the ground to see how it slopes.\n",
    "\n",
    "* Take a small step downhill.\n",
    "\n",
    "* Repeat until it is uphill in every direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-5]` Gradient descent steps\n",
    "\n",
    "* Start at a random point.\n",
    "\n",
    "* Until arrived at somewhere flat:\n",
    "\n",
    "    * find the slope\n",
    "    \n",
    "    * take a step downhill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-6]` Optimizing a model with a single weight\n",
    "\n",
    "![Optimizing a model with a single weight](ref3.%20Optimizing%20a%20model%20with%20a%20single%20weight.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[quiz-1]` Calculating model errors\n",
    "\n",
    "* Continue working with the network to predict transactions for a bank.\n",
    "\n",
    "* What is the error ($error = predicted - actual$) for the following network using the ReLU activation function when the input data is $[3, 2]$, and the actual value of the target, which tries to predict, is $5$? It may be helpful to get out a pen and piece of paper to calculate these values.\n",
    "\n",
    "    ![Calculating model errors](ref4.%20Calculating%20model%20errors.png)\n",
    "    \n",
    "    $\\Box$ $5$.\n",
    "    \n",
    "    $\\Box$ $6$.\n",
    "    \n",
    "    $\\boxtimes$ $11$.\n",
    "    \n",
    "    $\\Box$ $16$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[quiz-2]` Understanding how weights change model accuracy\n",
    "\n",
    "* Imagine making a prediction for a single data point. The actual value of the target is $7$. The weight going from `node_0` to the output is $2$, as shown below. If it is increased slightly, changing it to $2.01$, would the predictions become more accurate, less accurate, or stay the same?\n",
    "\n",
    "    ![Understanding how weights change model accuracy](ref5.%20Understanding%20how%20weights%20change%20model%20accuracy.png)\n",
    "    \n",
    "    $\\Box$ More accurate.\n",
    "    \n",
    "    $\\boxtimes$ Less accurate.\n",
    "    \n",
    "    $\\Box$ Stay the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[task-1]` Coding how weight changes affect the accuracy\n",
    "\n",
    "$\\blacktriangleright$ **Task diagram**\n",
    "\n",
    "![Coding how weight changes affect the accuracy](ref6.%20Coding%20how%20weight%20changes%20affect%20the%20accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:48.183282Z",
     "start_time": "2020-12-03T07:25:47.812286Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:48.190443Z",
     "start_time": "2020-12-03T07:25:48.185500Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_network(input_data_point, weights):\n",
    "    node_0_input = (input_data_point * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    node_1_input = (input_data_point * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    hidden_layer_values = np.array([node_0_output, node_1_output])\n",
    "    input_to_final_layer = (hidden_layer_values * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "\n",
    "    return (model_output)\n",
    "\n",
    "\n",
    "def relu(my_input):\n",
    "    return (max(0, my_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:48.250516Z",
     "start_time": "2020-12-03T07:25:48.242471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# The data point you will make a prediction for\n",
    "input_data = np.array([0, 3])\n",
    "\n",
    "# Sample weights\n",
    "weights_0 = {'node_0': [2, 1], 'node_1': [1, 2], 'output': [1, 1]}\n",
    "\n",
    "# The actual target value, used to calculate the error\n",
    "target_actual = 3\n",
    "\n",
    "# Make prediction using original weights\n",
    "model_output_0 = predict_with_network(input_data, weights_0)\n",
    "\n",
    "# Calculate error: error_0\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
    "weights_1 = {'node_0': [2, 1], 'node_1': [1, 0], 'output': [1, 1]}\n",
    "\n",
    "# Make prediction using new weights: model_output_1\n",
    "model_output_1 = predict_with_network(input_data, weights_1)\n",
    "\n",
    "# Calculate error: error_1\n",
    "error_1 = model_output_1 - target_actual\n",
    "\n",
    "# Print error_0 and error_1\n",
    "print(error_0)\n",
    "print(error_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]` Scaling up to multiple data points\n",
    "\n",
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:48.410937Z",
     "start_time": "2020-12-03T07:25:48.406548Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    np.array([0, 3]),\n",
    "    np.array([1, 2]),\n",
    "    np.array([-1, -2]),\n",
    "    np.array([4, 0])\n",
    "]\n",
    "\n",
    "weights_0 = {\n",
    "    'node_0': np.array([2, 1]),\n",
    "    'node_1': np.array([1, 2]),\n",
    "    'output': np.array([1, 1])\n",
    "}\n",
    "\n",
    "weights_1 = {\n",
    "    'node_0': np.array([2, 1]),\n",
    "    'node_1': np.array([1., 1.5]),\n",
    "    'output': np.array([1., 1.5])\n",
    "}\n",
    "\n",
    "target_actuals = [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.114916Z",
     "start_time": "2020-12-03T07:25:48.580256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.500000\n",
      "Mean squared error with weights_1: 49.890625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create model_output_0\n",
    "model_output_0 = []\n",
    "# Create model_output_1\n",
    "model_output_1 = []\n",
    "\n",
    "# Loop over input_data\n",
    "for row in input_data:\n",
    "    # Append prediction to model_output_0\n",
    "    model_output_0.append(predict_with_network(row, weights_0))\n",
    "\n",
    "    # Append prediction to model_output_1\n",
    "    model_output_1.append(predict_with_network(row, weights_1))\n",
    "\n",
    "# Calculate the mean squared error for model_output_0: mse_0\n",
    "mse_0 = mean_squared_error(target_actuals, model_output_0)\n",
    "\n",
    "# Calculate the mean squared error for model_output_1: mse_1\n",
    "mse_1 = mean_squared_error(target_actuals, model_output_1)\n",
    "\n",
    "# Print mse_0 and mse_1\n",
    "print(\"Mean squared error with weights_0: %f\" % mse_0)\n",
    "print(\"Mean squared error with weights_1: %f\" % mse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Gradient descent\n",
    "\n",
    "* If the slope is positive:\n",
    "\n",
    "    * going opposite the slope means moving to lower numbers\n",
    "    \n",
    "    * subtract the slope from the current value\n",
    "    \n",
    "    * too big a step might lead astray\n",
    "\n",
    "* Solution: *learning rate*\n",
    "\n",
    "    * update each weight by subtracting $learning\\ rate \\times slope$\n",
    "\n",
    "![Gradient descent](ref7.%20Gradient%20descent.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Slope calculation example\n",
    "\n",
    "* To calculate the slope for a weight, need to multiply:\n",
    "\n",
    "    * the slope of the loss function with respect to value at the node which has been feed into\n",
    "    \n",
    "    * the value of the node that feeds into the weight\n",
    "    \n",
    "    * the slope of the activation function with respect to the value which has been feed into\n",
    "\n",
    "* In this example, the slope of the mean-squared loss function with respect to prediction will be considered:    \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        {MSE}^{\\prime}\\ &=\\ \\left({\\left(Predicted\\ Value\\ -\\ Actual\\ Value\\right)}^{2}\\right)^{\\prime}\\\\\n",
    "        &=\\ 2\\ \\cdot\\ \\left(Predicted\\ Value\\ -\\ Actual\\ Value\\right)\\\\\n",
    "        &=\\ 2\\ \\cdot\\ Error\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "* In this example, the slope of the mean-squared loss function will be $2 \\cdot (6 - 10) = 2 \\cdot (-4)$, the value of the node that feeds into the weight is $3$, and no activation function needs to be considered. So the final multiplied slope for the weight will be $2 \\cdot (-4) \\cdot 3 = -24$.\n",
    "\n",
    "* In this example, if the learning rate is $0.01$, the new weight would be $2 - 0.01 \\cdot (-24) = 2.24$.\n",
    "\n",
    "![Slope calculation example](ref8.%20Slope%20calculation%20example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-3]` Network with two inputs affecting prediction\n",
    "\n",
    "![Network with two inputs affecting prediction](ref9.%20Network%20with%20two%20inputs%20affecting%20prediction.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-1]` Calculate slopes and update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.122804Z",
     "start_time": "2020-12-03T07:25:51.117557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "weights = np.array([1, 2])\n",
    "input_data = np.array([3, 4])\n",
    "target = 6\n",
    "learning_rate = 0.01\n",
    "\n",
    "preds = (weights * input_data).sum()\n",
    "error = preds - target\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.137392Z",
     "start_time": "2020-12-03T07:25:51.126182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 40])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = 2 * input_data * error\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.144099Z",
     "start_time": "2020-12-03T07:25:51.140440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "weights_updated = weights - learning_rate * gradient\n",
    "\n",
    "preds_updated = (weights_updated * input_data).sum()\n",
    "error_updated = preds_updated - target\n",
    "print(error_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[task-1]` Calculating slopes\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.149769Z",
     "start_time": "2020-12-03T07:25:51.146311Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.157698Z",
     "start_time": "2020-12-03T07:25:51.153449Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = np.array([1, 2, 3])\n",
    "\n",
    "weights = np.array([0, 2, 1])\n",
    "\n",
    "target = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.164440Z",
     "start_time": "2020-12-03T07:25:51.159875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 28 42]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the predictions: preds\n",
    "preds = (weights * input_data).sum()\n",
    "\n",
    "# Calculate the error: error\n",
    "error = preds - target\n",
    "\n",
    "# Calculate the slope: slope\n",
    "slope = 2 * error * input_data\n",
    "\n",
    "# Print the slope\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]` Improving model weights\n",
    "\n",
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.175401Z",
     "start_time": "2020-12-03T07:25:51.170580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5.04\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate: learning_rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Calculate the predictions: preds\n",
    "preds = (weights * input_data).sum()\n",
    "\n",
    "# Calculate the error: error\n",
    "error = preds - target\n",
    "\n",
    "# Calculate the slope: slope\n",
    "slope = 2 * input_data * error\n",
    "\n",
    "# Update the weights: weights_updated\n",
    "weights_updated = weights - learning_rate * slope\n",
    "\n",
    "# Get updated predictions: preds_updated\n",
    "preds_updated = (weights_updated * input_data).sum()\n",
    "\n",
    "# Calculate updated error: error_updated\n",
    "error_updated = preds_updated - target\n",
    "\n",
    "# Print the original error\n",
    "print(error)\n",
    "\n",
    "# Print the updated error\n",
    "print(error_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-3]` Making multiple updates to weights\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.942896Z",
     "start_time": "2020-12-03T07:25:51.178024Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:51.954482Z",
     "start_time": "2020-12-03T07:25:51.944819Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_error(input_data, target, weights):\n",
    "    preds = (weights * input_data).sum()\n",
    "    error = preds - target\n",
    "    return (error)\n",
    "\n",
    "\n",
    "def get_slope(input_data, target, weights):\n",
    "    error = get_error(input_data, target, weights)\n",
    "    slope = 2 * input_data * error\n",
    "    return (slope)\n",
    "\n",
    "\n",
    "def get_mse(input_data, target, weights):\n",
    "    errors = get_error(input_data, target, weights)\n",
    "    mse = np.mean(errors**2)\n",
    "    return (mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T03:47:06.967951Z",
     "start_time": "2020-11-01T03:47:06.815327Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T07:25:52.350681Z",
     "start_time": "2020-12-03T07:25:51.956954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_updates = 20\n",
    "mse_hist = []\n",
    "\n",
    "# Iterate over the number of updates\n",
    "for i in range(n_updates):\n",
    "    # Calculate the slope: slope\n",
    "    slope = get_slope(input_data, target, weights)\n",
    "\n",
    "    # Update the weights: weights\n",
    "    weights = weights - 0.01 * slope\n",
    "\n",
    "    # Calculate mse with new weights: mse\n",
    "    mse = get_mse(input_data, target, weights)\n",
    "\n",
    "    # Append the mse to mse_hist\n",
    "    mse_hist.append(mse)\n",
    "\n",
    "# Plot the mse history\n",
    "plt.plot(mse_hist)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-1]` Backpropagation\n",
    "\n",
    "* Allows gradient descent to update all weights in the neural network (by getting gradients for all weights).\n",
    "\n",
    "* This algorithm comes from the chain rule of calculus.\n",
    "\n",
    "* Important to understand the process, but generally, there is a library available that implements this.\n",
    "\n",
    "![Backpropagation](ref10.%20Backpropagation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Backpropagation process\n",
    "\n",
    "* Try to estimate the slope of the loss function with respect to each weight.\n",
    "\n",
    "* Do forward propagation to calculate predictions and errors.\n",
    "\n",
    "* Go back one layer at a time.\n",
    "\n",
    "* Gradients for weight is the product of:\n",
    "\n",
    "    * node value feeding into that weight\n",
    "    \n",
    "    * the slope of the loss function with respect to node it feeds into\n",
    "    \n",
    "    * the slope of activation function at the node it feeds into\n",
    "\n",
    "* It is also necessary to keep track of the slopes of the loss function with respect to node values.\n",
    "\n",
    "* The slope of node values is the sum of the slopes for all weights that come out of them.\n",
    "\n",
    "![Backpropagation process](ref11.%20Backpropagation%20process.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[quiz-1]` The relationship between the forward and the backward propagation\n",
    "\n",
    "* If it has been gone through $4$ iterations of calculating slopes (using backward propagation) and then updated weights, how many times must the forward propagation have been done?\n",
    "\n",
    "    $\\Box$ $0$.\n",
    "    \n",
    "    $\\Box$ $1$.\n",
    "    \n",
    "    $\\boxtimes$ $4$.\n",
    "    \n",
    "    $\\Box$ $8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[quiz-2]` Thinking about backward propagation\n",
    "\n",
    "* If the predictions were all exactly right, and the errors were all exactly $0$, the slope of the loss function with respect to these predictions would also be $0$. In that circumstance, which of the following statements would be correct?\n",
    "\n",
    "    $\\boxtimes$ The updates to all weights in the network would also be $0$.\n",
    "    \n",
    "    $\\Box$ The updates to all weights in the network would be dependent on the activation functions.\n",
    "    \n",
    "    $\\Box$ The updates to all weights in the network would be proportional to values from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-1]` Calculating slopes associated with any weight\n",
    "\n",
    "* Gradients for weight is the product of:\n",
    "\n",
    "    * node value feeding into that weight\n",
    "    \n",
    "    * the slope of activation function for the node being fed into\n",
    "    \n",
    "    * the slope of loss function w.r.t output node\n",
    "\n",
    "![Calculating slopes associated with any weight](ref12.%20Calculating%20slopes%20associated%20with%20any%20weight.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Backpropagation: Recap\n",
    "\n",
    "* Start at some random set of weights.\n",
    "\n",
    "* Use forward propagation to make a prediction.\n",
    "\n",
    "* Use backward propagation to calculate the slope of the loss function with respect to each weight.\n",
    "\n",
    "* Multiply that slope by the learning rate, and subtract from the current weights.\n",
    "\n",
    "* Keep going with that cycle until got to a flat part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-3]` What are the principles of stochastic gradient descent?\n",
    "\n",
    "* What are the principles of stochastic gradient descent?\n",
    "\n",
    "* It is common to calculate slopes on only a subset of the data (a batch).\n",
    "\n",
    "* Use a different batch of data to calculate the next update.\n",
    "\n",
    "* Start over from the beginning once all data is used.\n",
    "\n",
    "* Each time through the training data is called an epoch.\n",
    "\n",
    "* When slopes are calculated on one batch at a time, it is so-called stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice question for a round of backpropagation:\n",
    "\n",
    "* In the network shown below, forward propagation was done, and node values calculated as part of the forward propagation are shown in white. The weights are shown in black. Layers after the question mark show the slopes calculated as part of back-prop, rather than the forward-prop values. Those slope values are shown in purple.\n",
    "\n",
    "* This network again uses the ReLU activation function, so the slope of the activation function is $1$ for any node receiving a positive value as input. Assume the node being examined had a positive value (so the activation function's slope is $1$).\n",
    "    \n",
    "    ![A round of backpropagation_1](ref13.%20A%20round%20of%20backpropagation_1.png)\n",
    "\n",
    "* What is the slope needed to update the weight with the question mark?\n",
    "\n",
    "    ![A round of backpropagation_2](ref14.%20A%20round%20of%20backpropagation_2.png)\n",
    "\n",
    "    $\\Box$ $0$.\n",
    "    \n",
    "    $\\Box$ $2$.\n",
    "    \n",
    "    $\\boxtimes$ $6$.\n",
    "\n",
    "    $\\Box$ Not enough information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
