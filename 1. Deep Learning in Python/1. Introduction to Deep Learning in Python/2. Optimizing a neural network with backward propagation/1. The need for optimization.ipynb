{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "```\n",
    "###############################\n",
    "##                           ##\n",
    "##  Deep Learning in Python  ##\n",
    "##                           ##\n",
    "###############################\n",
    "\n",
    "ยง1 Introduction to Deep Learning in Python\n",
    "\n",
    "ยง1.2 Optimizing a neural network with backward propagation\n",
    "\n",
    "ยง1.2.1 The need for optimization\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "**1. How to measure the baseline for the neural network?**\n",
    "\n",
    "![A baseline neural network](ref1.%20A%20baseline%20neural%20network.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the challenges for the predictions with multiple points?**\n",
    "\n",
    "* Making accurate predictions gets more challenging with more points.\n",
    "\n",
    "* At any set of weights, there are many values of the error corresponding to the many points for making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "**3. What is the importance of the loss function?**\n",
    "\n",
    "* Aggregates errors in predictions from many data points into a single number for measuring the model's predictive performance.\n",
    "\n",
    "* A lower loss function value means a better model.\n",
    "\n",
    "* The loss function's goal is to find the weights that give the lowest value for the loss function by gradient descent.\n",
    "\n",
    "![Loss function](ref2.%20Loss%20function.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "**4. What are the steps of gradient descent?**\n",
    "\n",
    "$\\quad$ Start at a random point until got somewhere flat, find the slope, take a step downhill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. How to optimize a model with a single weight?**\n",
    "\n",
    "![Optimizing a model with a single weight](ref3.%20Optimizing%20a%20model%20with%20a%20single%20weight.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Practice question for calculating model errors:**\n",
    "\n",
    "* What is the error for the following network using the ReLU activation function when the input data is $[3, 2]$, and the actual value of the target is $5$?\n",
    "\n",
    "    > $Error = Predicted - Actual$\n",
    "\n",
    "    ![Calculating model errors](ref4.%20Calculating%20model%20errors.png)\n",
    "\n",
    "    $\\Box$ $5$.\n",
    "    \n",
    "    $\\Box$ $6$.\n",
    "    \n",
    "    $\\boxtimes$ $11$.\n",
    "\n",
    "    $\\Box$ $16$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Practice question for understanding how weights change model accuracy:**\n",
    "\n",
    "\n",
    "* Imagine you have to make a prediction for a single data point. The actual value of the target is $7$. The weight going from `node_0` to the output is $2$, as shown below. If you increased it slightly, changing it to $2.01$, would the predictions become more accurate, less accurate, or stay the same?\n",
    "\n",
    "    ![Understanding how weights change model accuracy](ref5.%20Understanding%20how%20weights%20change%20model%20accuracy.png)\n",
    "\n",
    "    $\\Box$ More accurate.\n",
    "    \n",
    "    $\\boxtimes$ Less accurate.\n",
    "\n",
    "    $\\Box$ Stay the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "**8. Practice exercises for the need for optimization:**\n",
    "\n",
    "$\\blacktriangleright$ **Diagram of the forward propagation:**\n",
    "\n",
    "![Coding how weight changes affect accuracy](ref6.%20Coding%20how%20weight%20changes%20affect%20accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T22:40:43.476628Z",
     "start_time": "2020-11-02T22:40:42.572825Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict_with_network(input_data_point, weights):\n",
    "    node_0_input = (input_data_point * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    node_1_input = (input_data_point * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    hidden_layer_values = np.array([node_0_output, node_1_output])\n",
    "    input_to_final_layer = (hidden_layer_values * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "\n",
    "    return (model_output)\n",
    "\n",
    "\n",
    "def relu(my_input):\n",
    "    return (max(0, my_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Weight changes affect accuracy practice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T22:40:43.491720Z",
     "start_time": "2020-11-02T22:40:43.478837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# The data point you will make a prediction for\n",
    "input_data = np.array([0, 3])\n",
    "\n",
    "# Sample weights\n",
    "weights_0 = {'node_0': [2, 1], 'node_1': [1, 2], 'output': [1, 1]}\n",
    "\n",
    "# The actual target value, used to calculate the error\n",
    "target_actual = 3\n",
    "\n",
    "# Make prediction using original weights\n",
    "model_output_0 = predict_with_network(input_data, weights_0)\n",
    "\n",
    "# Calculate error: error_0\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
    "weights_1 = {'node_0': [2, 1], 'node_1': [1, 0], 'output': [1, 1]}\n",
    "\n",
    "# Make prediction using new weights: model_output_1\n",
    "model_output_1 = predict_with_network(input_data, weights_1)\n",
    "\n",
    "# Calculate error: error_1\n",
    "error_1 = model_output_1 - target_actual\n",
    "\n",
    "# Print error_0 and error_1\n",
    "print(error_0)\n",
    "print(error_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T22:40:43.507869Z",
     "start_time": "2020-11-02T22:40:43.498828Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    np.array([0, 3]),\n",
    "    np.array([1, 2]),\n",
    "    np.array([-1, -2]),\n",
    "    np.array([4, 0])\n",
    "]\n",
    "\n",
    "weights_0 = {\n",
    "    'node_0': np.array([2, 1]),\n",
    "    'node_1': np.array([1, 2]),\n",
    "    'output': np.array([1, 1])\n",
    "}\n",
    "\n",
    "weights_1 = {\n",
    "    'node_0': np.array([2, 1]),\n",
    "    'node_1': np.array([1., 1.5]),\n",
    "    'output': np.array([1., 1.5])\n",
    "}\n",
    "\n",
    "target_actuals = [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Scaling up to multiple data points practice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T22:40:44.995573Z",
     "start_time": "2020-11-02T22:40:43.512821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.500000\n",
      "Mean squared error with weights_1: 49.890625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create model_output_0\n",
    "model_output_0 = []\n",
    "# Create model_output_1\n",
    "model_output_1 = []\n",
    "\n",
    "# Loop over input_data\n",
    "for row in input_data:\n",
    "    # Append prediction to model_output_0\n",
    "    model_output_0.append(predict_with_network(row, weights_0))\n",
    "\n",
    "    # Append prediction to model_output_1\n",
    "    model_output_1.append(predict_with_network(row, weights_1))\n",
    "\n",
    "# Calculate the mean squared error for model_output_0: mse_0\n",
    "mse_0 = mean_squared_error(target_actuals, model_output_0)\n",
    "\n",
    "# Calculate the mean squared error for model_output_1: mse_1\n",
    "mse_1 = mean_squared_error(target_actuals, model_output_1)\n",
    "\n",
    "# Print mse_0 and mse_1\n",
    "print(\"Mean squared error with weights_0: %f\" % mse_0)\n",
    "print(\"Mean squared error with weights_1: %f\" % mse_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
