{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-keras-model\" data-toc-modified-id=\"Creating-a-keras-model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Creating a keras model</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Model-building-steps\" data-toc-modified-id=\"[note-1]-Model-building-steps-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>[note-1]</code> Model building steps</a></span></li><li><span><a href=\"#[code-1]-Model-specification\" data-toc-modified-id=\"[code-1]-Model-specification-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>[code-1]</code> Model specification</a></span></li><li><span><a href=\"#[quiz-1]-Understanding-the-data\" data-toc-modified-id=\"[quiz-1]-Understanding-the-data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>[quiz-1]</code> Understanding the data</a></span></li><li><span><a href=\"#[task-1]-Specifying-a-model\" data-toc-modified-id=\"[task-1]-Specifying-a-model-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>[task-1]</code> Specifying a model</a></span></li></ul></li><li><span><a href=\"#Compiling-and-fitting-a-model\" data-toc-modified-id=\"Compiling-and-fitting-a-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compiling and fitting a model</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Why-need-to-compile-the-model\" data-toc-modified-id=\"[note-1]-Why-need-to-compile-the-model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><code>[note-1]</code> Why need to compile the model</a></span></li><li><span><a href=\"#[code-1]-Compiling-a-model\" data-toc-modified-id=\"[code-1]-Compiling-a-model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><code>[code-1]</code> Compiling a model</a></span></li><li><span><a href=\"#[note-2]-What-is-fitting-a-model\" data-toc-modified-id=\"[note-2]-What-is-fitting-a-model-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><code>[note-2]</code> What is fitting a model</a></span></li><li><span><a href=\"#[code-2]-Fitting-a-model\" data-toc-modified-id=\"[code-2]-Fitting-a-model-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span><code>[code-2]</code> Fitting a model</a></span></li><li><span><a href=\"#[task-1]-Compiling-the-model\" data-toc-modified-id=\"[task-1]-Compiling-the-model-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span><code>[task-1]</code> Compiling the model</a></span></li><li><span><a href=\"#[task-2]-Fitting-the-model\" data-toc-modified-id=\"[task-2]-Fitting-the-model-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span><code>[task-2]</code> Fitting the model</a></span></li></ul></li><li><span><a href=\"#Classification-models\" data-toc-modified-id=\"Classification-models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Classification models</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Classification\" data-toc-modified-id=\"[note-1]-Classification-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>[note-1]</code> Classification</a></span></li><li><span><a href=\"#[note-2]-Transforming-to-categorical\" data-toc-modified-id=\"[note-2]-Transforming-to-categorical-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><code>[note-2]</code> Transforming to categorical</a></span></li><li><span><a href=\"#[code-1]-Classification\" data-toc-modified-id=\"[code-1]-Classification-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><code>[code-1]</code> Classification</a></span></li><li><span><a href=\"#[quiz-1]-Understanding-the-classification-data\" data-toc-modified-id=\"[quiz-1]-Understanding-the-classification-data-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>[quiz-1]</code> Understanding the classification data</a></span></li><li><span><a href=\"#[task-1]-Last-steps-in-classification-models\" data-toc-modified-id=\"[task-1]-Last-steps-in-classification-models-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span><code>[task-1]</code> Last steps in classification models</a></span></li></ul></li><li><span><a href=\"#Using-models\" data-toc-modified-id=\"Using-models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Using models</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-to-use-models?\" data-toc-modified-id=\"How-to-use-models?-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>How to use models?</a></span></li><li><span><a href=\"#Code-of-saving,-reloading,-and-using-the-model-reloaded:\" data-toc-modified-id=\"Code-of-saving,-reloading,-and-using-the-model-reloaded:-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Code of saving, reloading, and using the model reloaded:</a></span></li><li><span><a href=\"#Practice-exercises-for-using-models:\" data-toc-modified-id=\"Practice-exercises-for-using-models:-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Practice exercises for using models:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Model building steps\n",
    "\n",
    "* Specify Architecture\n",
    "\n",
    "* Compile\n",
    "\n",
    "* Fit\n",
    "\n",
    "* Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[code-1]` Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.033795Z",
     "start_time": "2021-05-02T23:44:56.457982Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "predictors = np.loadtxt('../Datasets/1. Hourly wages predictors data.csv',\n",
    "                        delimiter=',')\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[quiz-1]` Understanding the data\n",
    "\n",
    "* It will be started soon to building models in Keras to predict wages based on various professional and demographic factors by the next steps. Before starting building a model, it's good to understand the data by performing some exploratory analysis.\n",
    "\n",
    "* It is recommended to use the `.head()` and `.describe()` methods in the IPython Shell to quickly overview the DataFrame.\n",
    "\n",
    "* The target variable which will be predicting is `wage_per_hour`. Some of the predictor variables are binary indicators, where a value of `1` represents `True`, and `0` represents `False`.\n",
    "\n",
    "* Of the nine predictor variables in the DataFrame, how many are binary indicators? The min and max values, as shown by `.describe()` will be informative here. How many binary indicator predictors are there?\n",
    "\n",
    "    $\\Box$ $0$.\n",
    "\n",
    "    $\\Box$ $5$.\n",
    "\n",
    "    $\\boxtimes$ $6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.053722Z",
     "start_time": "2021-05-02T23:45:26.048867Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.097158Z",
     "start_time": "2021-05-02T23:45:26.067838Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/2. Hourly wages.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Quiz solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.167242Z",
     "start_time": "2021-05-02T23:45:26.118680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.283046Z",
     "start_time": "2021-05-02T23:45:26.172466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.024064</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>13.018727</td>\n",
       "      <td>17.822097</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.139097</td>\n",
       "      <td>0.384360</td>\n",
       "      <td>2.615373</td>\n",
       "      <td>12.379710</td>\n",
       "      <td>11.726573</td>\n",
       "      <td>0.498767</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage_per_hour       union  education_yrs  experience_yrs         age  \\\n",
       "count     534.000000  534.000000     534.000000      534.000000  534.000000   \n",
       "mean        9.024064    0.179775      13.018727       17.822097   36.833333   \n",
       "std         5.139097    0.384360       2.615373       12.379710   11.726573   \n",
       "min         1.000000    0.000000       2.000000        0.000000   18.000000   \n",
       "25%         5.250000    0.000000      12.000000        8.000000   28.000000   \n",
       "50%         7.780000    0.000000      12.000000       15.000000   35.000000   \n",
       "75%        11.250000    0.000000      15.000000       26.000000   44.000000   \n",
       "max        44.500000    1.000000      18.000000       55.000000   64.000000   \n",
       "\n",
       "           female        marr       south  manufacturing  construction  \n",
       "count  534.000000  534.000000  534.000000     534.000000    534.000000  \n",
       "mean     0.458801    0.655431    0.292135       0.185393      0.044944  \n",
       "std      0.498767    0.475673    0.455170       0.388981      0.207375  \n",
       "min      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "25%      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "50%      0.000000    1.000000    0.000000       0.000000      0.000000  \n",
       "75%      1.000000    1.000000    1.000000       0.000000      0.000000  \n",
       "max      1.000000    1.000000    1.000000       1.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.330230Z",
     "start_time": "2021-05-02T23:45:26.292881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 binary indicator predictors here.\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "count = 0\n",
    "for i in range(len(cols)):\n",
    "    if ((len(df.iloc[:, i].unique()) == 2)\n",
    "            and (df.iloc[:, i].unique()[0] in [0, 1])\n",
    "            and (df.iloc[:, i].unique()[1] in [0, 1])):\n",
    "        count += 1\n",
    "    else:\n",
    "        pass\n",
    "print('There are {} binary indicator predictors here.'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:40:27.891420Z",
     "start_time": "2020-11-06T01:40:27.865712Z"
    }
   },
   "source": [
    "## `[task-1]` Specifying a model\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.346870Z",
     "start_time": "2021-05-02T23:45:26.341199Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:53:56.613690Z",
     "start_time": "2020-11-06T01:53:56.571659Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.398866Z",
     "start_time": "2021-05-02T23:45:26.377630Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/2. Hourly wages.csv')\n",
    "\n",
    "target = df.iloc[:, 0].to_numpy()\n",
    "predictors = df.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T03:57:16.896924Z",
     "start_time": "2020-11-06T03:57:16.881936Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.483507Z",
     "start_time": "2021-05-02T23:45:26.410249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Why need to compile the model\n",
    "\n",
    "* Specify the optimizer:\n",
    "\n",
    "\t* many options and mathematically complex\n",
    "\t\n",
    "\t* `'adam'` is usually a good choice\n",
    "\n",
    "* Loss function:\n",
    "\n",
    "    * `'mean_squared_error'` common for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[code-1]` Compiling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:26.588357Z",
     "start_time": "2021-05-02T23:45:26.497927Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "predictors = np.loadtxt('../Datasets/1. Hourly wages predictors data.csv',\n",
    "                        delimiter=',')\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` What is fitting a model\n",
    "\n",
    "* Apply backpropagation and gradient descent with the data to update the weights.\n",
    "\n",
    "* Scaling data before fitting can ease optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-2]` Fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:27.727764Z",
     "start_time": "2021-05-02T23:45:26.604825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 2ms/step - loss: 68.6947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadec803690>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.loadtxt('../Datasets/3. Hourly wages target data.csv',\n",
    "                    delimiter=',')\n",
    "\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T16:23:14.346961Z",
     "start_time": "2020-11-07T16:23:14.311501Z"
    }
   },
   "source": [
    "## `[task-1]` Compiling the model\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:27.743444Z",
     "start_time": "2021-05-02T23:45:27.739020Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:53:56.613690Z",
     "start_time": "2020-11-06T01:53:56.571659Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:27.765019Z",
     "start_time": "2021-05-02T23:45:27.747013Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/2. Hourly wages.csv')\n",
    "\n",
    "predictors = df.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T03:57:16.896924Z",
     "start_time": "2020-11-06T03:57:16.881936Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:46:31.221353Z",
     "start_time": "2021-05-02T23:46:31.124253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]` Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:29.125886Z",
     "start_time": "2021-05-02T23:45:21.797Z"
    }
   },
   "outputs": [],
   "source": [
    "target = df.iloc[:, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:29.131324Z",
     "start_time": "2021-05-02T23:45:23.417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Classification\n",
    "\n",
    "* `'categorical_crossentropy'` loss function.\n",
    "\n",
    "* Similar to log loss: \n",
    "\n",
    "    * lower is better\n",
    "\n",
    "* Add `metrics = ['accuracy']` to compile step for easy-to-understand diagnostics.\n",
    "\n",
    "* The output layer has a separate node for each possible outcome and uses `'softmax'` activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Transforming to categorical\n",
    "\n",
    "![Transforming to categorical](../Figures/1.%20Transforming%20to%20categorical.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[code-1]` Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:47:47.858888Z",
     "start_time": "2021-05-02T23:47:34.592072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4003/4003 [==============================] - 12s 3ms/step - loss: 0.6631 - accuracy: 0.6073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faded295110>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def data_preparation(df):\n",
    "    df = df.reindex(columns=[\n",
    "        'SHOT_CLOCK', 'DRIBBLES', 'TOUCH_TIME', 'SHOT_DIST', 'CLOSE_DEF_DIST',\n",
    "        'SHOT_RESULT'\n",
    "    ])\n",
    "    df['SHOT_CLOCK'] = df['SHOT_CLOCK'].fillna(0)\n",
    "    df['SHOT_RESULT'].replace('missed', 0, inplace=True)\n",
    "    df['SHOT_RESULT'].replace('made', 1, inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Datasets/4. Basketball shot log.csv')\n",
    "data = data_preparation(data)\n",
    "\n",
    "predictors = data.drop(['shot_result'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "target = to_categorical(data.shot_result)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T22:39:50.519204Z",
     "start_time": "2020-11-08T22:39:49.989831Z"
    }
   },
   "source": [
    "## `[quiz-1]` Understanding the classification data\n",
    "\n",
    "* To start modeling with a new dataset for a classification problem. This data includes information about passengers on the Titanic. Use predictors such as `age`, `fare`, and where each passenger embarked from to predict who will survive. This data is from [a tutorial on data science competitions](https://www.kaggle.com/c/titanic). Look [here](https://www.kaggle.com/c/titanic/data) for descriptions of the features.\n",
    "\n",
    "* It's smart to review the maximum and minimum values of each variable to ensure the data isn't misformatted or corrupted. What was the maximum age of passengers on the Titanic? Use the `.describe()` method in the IPython Shell to answer this question.\n",
    "\n",
    "    $\\Box$ $29.699$.\n",
    "\n",
    "    $\\boxtimes$ $80$.\n",
    "\n",
    "    $\\Box$ $891$.\n",
    "\n",
    "    $\\Box$ It is not listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T22:42:05.949159Z",
     "start_time": "2020-11-08T22:42:05.913632Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:31.615117Z",
     "start_time": "2021-05-02T23:45:31.611886Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T22:42:06.764181Z",
     "start_time": "2020-11-08T22:42:06.026393Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:32.794037Z",
     "start_time": "2021-05-02T23:45:32.769728Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/5. Titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Quiz solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:33.680505Z",
     "start_time": "2021-05-02T23:45:33.658961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1            False   \n",
       "1         1       1  38.0      1      0  71.2833     0            False   \n",
       "2         1       3  26.0      0      0   7.9250     0            False   \n",
       "3         1       1  35.0      1      0  53.1000     0            False   \n",
       "4         0       3  35.0      0      0   8.0500     1            False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:33.771037Z",
     "start_time": "2021-05-02T23:45:33.759326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.699118\n",
       "std       13.002015\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       29.699118\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:33.844788Z",
     "start_time": "2021-05-02T23:45:33.838715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum age of passengers on the Titanic is 80.\n"
     ]
    }
   ],
   "source": [
    "max_age = int(df['age'].max())\n",
    "print('The maximum age of passengers on the Titanic is {}.'.format(max_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T16:23:14.346961Z",
     "start_time": "2020-11-07T16:23:14.311501Z"
    }
   },
   "source": [
    "## `[task-1]` Last steps in classification models\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:48:23.521816Z",
     "start_time": "2021-05-02T23:48:23.473052Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:53:56.613690Z",
     "start_time": "2020-11-06T01:53:56.571659Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:48:26.160726Z",
     "start_time": "2021-05-02T23:48:26.080090Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/5. Titanic.csv')\n",
    "\n",
    "df['age_was_missing'].replace(False, 0, inplace=True)\n",
    "df['age_was_missing'].replace(True, 1, inplace=True)\n",
    "\n",
    "predictors = df.drop(['survived'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Classification models practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:48:30.788890Z",
     "start_time": "2021-05-02T23:48:29.733886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 5ms/step - loss: 4.3042 - accuracy: 0.5770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadd18eacd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## How to use models?\n",
    "\n",
    "* Save.\n",
    "\n",
    "* Reload.\n",
    "\n",
    "* Make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## Code of saving, reloading, and using the model reloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:40.234484Z",
     "start_time": "2021-05-02T23:45:40.199190Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dense' from 'keras.layers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-316aabaa477e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dense' from 'keras.layers' (unknown location)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "data = pd.read_csv('../Datasets/4. Basketball shot log.csv')\n",
    "\n",
    "\n",
    "def data_preparation(df):\n",
    "    df = df.reindex(columns=[\n",
    "        'SHOT_CLOCK', 'DRIBBLES', 'TOUCH_TIME', 'SHOT_DIST', 'CLOSE_DEF_DIST',\n",
    "        'SHOT_RESULT'\n",
    "    ])\n",
    "    df['SHOT_CLOCK'] = df['SHOT_CLOCK'].fillna(0)\n",
    "    df['SHOT_RESULT'].replace('missed', 0, inplace=True)\n",
    "    df['SHOT_RESULT'].replace('made', 1, inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "df = data_preparation(data)\n",
    "predictors = df.drop(['shot_result'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "target = to_categorical(df.shot_result)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:40.402283Z",
     "start_time": "2021-05-02T23:45:40.369445Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3ccb8f473008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ref7. Model file.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ref7. Model file.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.models'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('ref7. Model file.h5')\n",
    "my_model = load_model('ref7. Model file.h5')\n",
    "\n",
    "predictions = my_model.predict(predictors)\n",
    "probability_true = predictions[:, 1]\n",
    "probability_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:40.425243Z",
     "start_time": "2021-05-02T23:45:40.388Z"
    }
   },
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T16:23:14.346961Z",
     "start_time": "2020-11-07T16:23:14.311501Z"
    }
   },
   "source": [
    "## Practice exercises for using models:\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:41.390782Z",
     "start_time": "2021-05-02T23:45:41.369952Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dense' from 'keras.layers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-818b7a4ab4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dense' from 'keras.layers' (unknown location)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:53:56.613690Z",
     "start_time": "2020-11-06T01:53:56.571659Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:42.776824Z",
     "start_time": "2021-05-02T23:45:42.728766Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d16766a05cdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Datasets/6. Titanic predictors data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Datasets/5. Titanic.csv')\n",
    "\n",
    "df.replace(False, 0, inplace=True)\n",
    "df.replace(True, 1, inplace=True)\n",
    "\n",
    "predictors = df.drop(['survived'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "pred_data = pd.read_csv('../Datasets/6. Titanic predictors data.csv')\n",
    "pred_data.replace(False, 0, inplace=True)\n",
    "pred_data.replace(True, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Making predictions practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T23:45:43.667637Z",
     "start_time": "2021-05-02T23:45:43.576084Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 891\n  y sizes: 534\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-95c87f140534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculate predictions: predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 891\n  y sizes: 534\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# Specify, compile, and fit the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols, )))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:, 1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
