{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Understanding-model-optimization\" data-toc-modified-id=\"Understanding-model-optimization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Understanding model optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Why-optimization-is-hard\" data-toc-modified-id=\"[note-1]-Why-optimization-is-hard-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>[note-1]</code> Why optimization is hard</a></span></li><li><span><a href=\"#[code-1]-Stochastic-gradient-descent\" data-toc-modified-id=\"[code-1]-Stochastic-gradient-descent-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>[code-1]</code> Stochastic gradient descent</a></span></li><li><span><a href=\"#[note-2]-The-dying-neuron-problem\" data-toc-modified-id=\"[note-2]-The-dying-neuron-problem-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>[note-2]</code> The dying neuron problem</a></span></li><li><span><a href=\"#[note-3]-Vanishing-gradients\" data-toc-modified-id=\"[note-3]-Vanishing-gradients-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>[note-3]</code> Vanishing gradients</a></span></li><li><span><a href=\"#[quiz-1]-Diagnosing-optimization-problems\" data-toc-modified-id=\"[quiz-1]-Diagnosing-optimization-problems-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><code>[quiz-1]</code> Diagnosing optimization problems</a></span></li><li><span><a href=\"#[task-1]-Changing-optimization-parameters\" data-toc-modified-id=\"[task-1]-Changing-optimization-parameters-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span><code>[task-1]</code> Changing optimization parameters</a></span></li></ul></li><li><span><a href=\"#Model-validation\" data-toc-modified-id=\"Model-validation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Validation-in-deep-learning\" data-toc-modified-id=\"[note-1]-Validation-in-deep-learning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><code>[note-1]</code> Validation in deep learning</a></span></li><li><span><a href=\"#[code-1]-Model-validation\" data-toc-modified-id=\"[code-1]-Model-validation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><code>[code-1]</code> Model validation</a></span></li><li><span><a href=\"#[code-2]-Early-stopping\" data-toc-modified-id=\"[code-2]-Early-stopping-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><code>[code-2]</code> Early stopping</a></span></li><li><span><a href=\"#[note-2]-Experimentation\" data-toc-modified-id=\"[note-2]-Experimentation-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span><code>[note-2]</code> Experimentation</a></span></li><li><span><a href=\"#[task-1]-Evaluating-model-accuracy-on-a-validation-dataset\" data-toc-modified-id=\"[task-1]-Evaluating-model-accuracy-on-a-validation-dataset-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span><code>[task-1]</code> Evaluating model accuracy on a validation dataset</a></span></li><li><span><a href=\"#[task-2]-Early-stopping:-optimizing-the-optimization\" data-toc-modified-id=\"[task-2]-Early-stopping:-optimizing-the-optimization-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span><code>[task-2]</code> Early stopping: optimizing the optimization</a></span></li><li><span><a href=\"#[task-3]-Experimenting-with-wider-networks\" data-toc-modified-id=\"[task-3]-Experimenting-with-wider-networks-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span><code>[task-3]</code> Experimenting with wider networks</a></span></li><li><span><a href=\"#[task-4]-Adding-layers-to-a-network\" data-toc-modified-id=\"[task-4]-Adding-layers-to-a-network-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span><code>[task-4]</code> Adding layers to a network</a></span></li></ul></li><li><span><a href=\"#Thinking-about-model-capacity\" data-toc-modified-id=\"Thinking-about-model-capacity-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Thinking about model capacity</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Overfitting\" data-toc-modified-id=\"[note-1]-Overfitting-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><code>[note-1]</code> Overfitting</a></span></li><li><span><a href=\"#[note-2]-Workflow-for-optimizing-model-capacity\" data-toc-modified-id=\"[note-2]-Workflow-for-optimizing-model-capacity-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><code>[note-2]</code> Workflow for optimizing model capacity</a></span></li><li><span><a href=\"#[note-3]-Sequential-experiments\" data-toc-modified-id=\"[note-3]-Sequential-experiments-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><code>[note-3]</code> Sequential experiments</a></span></li><li><span><a href=\"#[quiz-1]-Practice-question-for-experimenting-with-model-structures:\" data-toc-modified-id=\"[quiz-1]-Practice-question-for-experimenting-with-model-structures:-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>[quiz-1]</code> Practice question for experimenting with model structures:</a></span></li></ul></li><li><span><a href=\"#Stepping-up-to-images\" data-toc-modified-id=\"Stepping-up-to-images-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Stepping up to images</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Recognizing-handwritten-digits\" data-toc-modified-id=\"[note-1]-Recognizing-handwritten-digits-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><code>[note-1]</code> Recognizing handwritten digits</a></span></li><li><span><a href=\"#[task-1]-Building-an-own-digit-recognition-model\" data-toc-modified-id=\"[task-1]-Building-an-own-digit-recognition-model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span><code>[task-1]</code> Building an own digit recognition model</a></span></li></ul></li><li><span><a href=\"#Final-thoughts\" data-toc-modified-id=\"Final-thoughts-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Final thoughts</a></span><ul class=\"toc-item\"><li><span><a href=\"#[note-1]-Next-steps\" data-toc-modified-id=\"[note-1]-Next-steps-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><code>[note-1]</code> Next steps</a></span></li></ul></li><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Requirements</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Why optimization is hard\n",
    "\n",
    "* Simultaneously optimizing 1000s of parameters with complex relationships.\n",
    "\n",
    "* Updates may not improve the model meaningfully.\n",
    "\n",
    "* Updates could be too small (if the learning rate is low) or too large (if the learning rate is high)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-1]` Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:23.057507Z",
     "start_time": "2021-05-03T23:28:43.732797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4003/4003 [==============================] - 9s 2ms/step - loss: 0.7773\n",
      "4003/4003 [==============================] - 9s 2ms/step - loss: 0.6752\n",
      "4003/4003 [==============================] - 9s 2ms/step - loss: nan     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def data_preparation(data):\n",
    "    df = data.reindex(columns=[\n",
    "        'SHOT_CLOCK', 'DRIBBLES', 'TOUCH_TIME', 'SHOT_DIST', 'CLOSE_DEF_DIST',\n",
    "        'SHOT_RESULT'\n",
    "    ])\n",
    "    df['SHOT_CLOCK'] = df['SHOT_CLOCK'].fillna(0)\n",
    "    df['SHOT_RESULT'].replace('missed', 0, inplace=True)\n",
    "    df['SHOT_RESULT'].replace('made', 1, inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Datasets/1. Basketball shot log.csv')\n",
    "df = data_preparation(data)\n",
    "\n",
    "predictors = df.drop(['shot_result'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "target = to_categorical(df.shot_result)\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "\n",
    "def get_new_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return (model)\n",
    "\n",
    "\n",
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "# loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    model = get_new_model()\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` The dying neuron problem\n",
    "\n",
    "![The dying neuron problem](../Figures/1.%20The%20dying%20neuron%20problem.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-3]` Vanishing gradients\n",
    "\n",
    "* It occurs when many layers have very small slopes (*e.g., due to being on at part of tanh curve*).\n",
    "\n",
    "* In deep networks, updates to backpropagation were close to 0.\n",
    "\n",
    "![Vanishing gradients](../Figures/2.%20Vanishing%20gradient.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[quiz-1]` Diagnosing optimization problems\n",
    "\n",
    "* Which of the following could prevent a model from showing an improved loss in its first few epochs?\n",
    "\n",
    "    $\\Box$ Learning rate too low.\n",
    "\n",
    "    $\\Box$ Learning rate too high.\n",
    "\n",
    "    $\\Box$ Poor choice of the activation function.\n",
    "\n",
    "    $\\boxtimes$ All of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-1]` Changing optimization parameters\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:24:42.598710Z",
     "start_time": "2021-05-04T00:24:42.577767Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:24:44.991801Z",
     "start_time": "2021-05-04T00:24:44.955710Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/2. Titanic.csv')\n",
    "\n",
    "df.replace(False, 0, inplace=True)\n",
    "df.replace(True, 1, inplace=True)\n",
    "\n",
    "predictors = df.drop(['survived'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "target = to_categorical(df.survived)\n",
    "input_shape = (n_cols, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:24:47.474820Z",
     "start_time": "2021-05-04T00:24:47.468673Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:24:53.574036Z",
     "start_time": "2021-05-04T00:24:49.835162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "28/28 [==============================] - 1s 4ms/step - loss: 4.2704\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "28/28 [==============================] - 1s 6ms/step - loss: 3.5053\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "28/28 [==============================] - 1s 3ms/step - loss: 21689306384020611072.0000\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n' % lr)\n",
    "\n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "\n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Validation in deep learning\n",
    "\n",
    "* Commonly use validation split rather than cross-validation.\n",
    "\n",
    "* Deep learning is widely used on large datasets.\n",
    "\n",
    "* A single validation score is based on a large amount of data and is reliable.\n",
    "\n",
    "* Repeated training from cross-validation would take a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-1]` Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:24:57.398679Z",
     "start_time": "2021-05-04T00:24:55.533388Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_11 is incompatible with the layer: expected axis -1 of input shape to have value 10 but received input with shape (None, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9cf0fb20c926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/haozhang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_11 is incompatible with the layer: expected axis -1 of input shape to have value 10 but received input with shape (None, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def data_preparation(data):\n",
    "    df = data.reindex(columns=[\n",
    "        'SHOT_CLOCK', 'DRIBBLES', 'TOUCH_TIME', 'SHOT_DIST', 'CLOSE_DEF_DIST',\n",
    "        'SHOT_RESULT'\n",
    "    ])\n",
    "    df['SHOT_CLOCK'] = df['SHOT_CLOCK'].fillna(0)\n",
    "    df['SHOT_RESULT'].replace('missed', 0, inplace=True)\n",
    "    df['SHOT_RESULT'].replace('made', 1, inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Datasets/1. Basketball shot log.csv')\n",
    "df = data_preparation(data)\n",
    "predictors = df.drop(['shot_result'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "target = to_categorical(df.shot_result)\n",
    "model = get_new_model()\n",
    "\n",
    "\n",
    "def get_new_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return (model)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:25:41.238709Z",
     "start_time": "2021-05-04T00:25:41.159156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10.8,  2. ,  1.9,  7.7,  1.3],\n",
       "        [ 3.4,  0. ,  0.8, 28.2,  6.1],\n",
       "        [ 0. ,  3. ,  2.7, 10.1,  0.9],\n",
       "        ...,\n",
       "        [23. ,  2. ,  4.2, 16.9,  4.2],\n",
       "        [ 9.1,  4. ,  4.5, 18.3,  3. ],\n",
       "        [ 0. ,  5. ,  4.7,  5.1,  2.3]]),\n",
       " array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[code-2]` Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.362648Z",
     "start_time": "2021-05-03T23:28:58.279Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(predictors,\n",
    "          target,\n",
    "          validation_split=0.3,\n",
    "          epochs=20,\n",
    "          callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Experimentation\n",
    "\n",
    "* Experiment with different architectures.\n",
    "\n",
    "* More layers.\n",
    "\n",
    "* Fewer layers.\n",
    "\n",
    "* Layers with more nodes.\n",
    "\n",
    "* Layers with fewer nodes.\n",
    "\n",
    "* Creating a great model requires experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-1]` Evaluating model accuracy on a validation dataset\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.365864Z",
     "start_time": "2021-05-03T23:29:00.959Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.370602Z",
     "start_time": "2021-05-03T23:29:02.291Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/2. Titanic.csv')\n",
    "\n",
    "df.replace(False, 0, inplace=True)\n",
    "df.replace(True, 1, inplace=True)\n",
    "\n",
    "predictors = df.drop(['survived'], axis=1).to_numpy()\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "target = to_categorical(df.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.373171Z",
     "start_time": "2021-05-03T23:29:03.566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-2]` Early stopping: optimizing the optimization\n",
    "\n",
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.376977Z",
     "start_time": "2021-05-03T23:29:05.498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,\n",
    "          target,\n",
    "          validation_split=0.3,\n",
    "          epochs=30,\n",
    "          callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-3]` Experimenting with wider networks\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.384252Z",
     "start_time": "2021-05-03T23:29:06.907Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.392565Z",
     "start_time": "2021-05-03T23:29:08.060Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model_1 = get_new_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Task practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.404232Z",
     "start_time": "2021-05-03T23:29:09.474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors,\n",
    "                               target,\n",
    "                               epochs=15,\n",
    "                               validation_split=0.2,\n",
    "                               callbacks=[early_stopping_monitor],\n",
    "                               verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors,\n",
    "                               target,\n",
    "                               epochs=15,\n",
    "                               validation_split=0.2,\n",
    "                               callbacks=[early_stopping_monitor],\n",
    "                               verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r',\n",
    "         model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-4]` Adding layers to a network\n",
    "\n",
    "$\\blacktriangleright$ **Code pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.407784Z",
     "start_time": "2021-05-03T23:29:10.850Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model_1 = get_new_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T07:48:15.812784Z",
     "start_time": "2020-11-14T07:48:15.802491Z"
    }
   },
   "source": [
    "$\\blacktriangleright$ **Network layers adding practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.411282Z",
     "start_time": "2021-05-03T23:29:12.127Z"
    }
   },
   "outputs": [],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors,\n",
    "                               target,\n",
    "                               epochs=20,\n",
    "                               validation_split=0.4,\n",
    "                               callbacks=[early_stopping_monitor],\n",
    "                               verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors,\n",
    "                               target,\n",
    "                               epochs=20,\n",
    "                               validation_split=0.4,\n",
    "                               callbacks=[early_stopping_monitor],\n",
    "                               verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r',\n",
    "         model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking about model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Overfitting\n",
    "\n",
    "![Overfitting](../Figures/3.%20Overfitting.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[note-2]` Workflow for optimizing model capacity\n",
    "\n",
    "* Start with a small network.\n",
    "\n",
    "* Gradually increase capacity.\n",
    "\n",
    "* Keep increasing capacity until the validation score is no longer improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T08:25:58.664966Z",
     "start_time": "2020-11-14T08:25:43.842347Z"
    }
   },
   "source": [
    "## `[note-3]` Sequential experiments\n",
    "\n",
    "![Sequential experiments](../Figures/4.%20Sequential%20experiments.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T08:26:09.564952Z",
     "start_time": "2020-11-14T08:25:58.683149Z"
    }
   },
   "source": [
    "## `[quiz-1]` Practice question for experimenting with model structures:\n",
    "\n",
    "* An experiment has run where has compared two networks that were identical except that the 2nd network had an extra hidden layer. It could be seen that this 2nd network (the deeper network) had better performance. Given that, which of the following would be a good experiment to run next for even better performance?\n",
    "\n",
    "    $\\Box$ Try a new network with fewer layers than anything you have tried yet.\n",
    "    \n",
    "    $\\boxtimes$ Use more units in each hidden layer.\n",
    "    \n",
    "    $\\Box$ Use fewer units in each hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepping up to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Recognizing handwritten digits\n",
    "\n",
    "* MNIST dataset.\n",
    "\n",
    "* 28 x 28 grid flattened to 784 values for each image.\n",
    "\n",
    "* Value in each part of the array denotes the darkness of that pixel.\n",
    "\n",
    "![Recognizing handwritten digits](../Figures/5.%20Recognizing%20handwritten%20digits.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[task-1]` Building an own digit recognition model\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.414347Z",
     "start_time": "2021-05-03T23:29:23.038Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.416967Z",
     "start_time": "2021-05-03T23:29:24.273Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/3. MNIST.csv', header=None)\n",
    "X = df.iloc[:, 1:].to_numpy()\n",
    "y = to_categorical(df.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Evaluating model accuracy on validation dataset practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T23:29:29.420733Z",
     "start_time": "2021-05-03T23:29:25.727Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(784, )))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "## `[note-1]` Next steps\n",
    "\n",
    "* Start with standard prediction problems on tables of numbers.\n",
    "\n",
    "* Images (with convolutional neural networks) are common next steps.\n",
    "\n",
    "* [keras.io](https://keras.io) for excellent documentation.\n",
    "\n",
    "* The graphical processing unit (GPU) provides dramatic speedups in model training times.\n",
    "\n",
    "* Need a CUDA-compatible GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T00:28:44.949795Z",
     "start_time": "2021-05-04T00:28:44.911088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "##                     ##\n",
      "##  python==3.7.9      ##\n",
      "##  pandas==1.2.1      ##\n",
      "##  tensorflow==2.4.1  ##\n",
      "##  matplotlib==3.3.4  ##\n",
      "##                     ##\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "\n",
    "python_version = ('python=={}'.format(python_version()))\n",
    "pandas_version = ('pandas=={}'.format(pd.__version__))\n",
    "tensorflow_version = ('tensorflow=={}'.format(tf.__version__))\n",
    "matplotlib_version = ('matplotlib=={}'.format(matplotlib.__version__))\n",
    "\n",
    "writepath = '../../requirements.txt'\n",
    "requirements = []\n",
    "packages = [pandas_version, tensorflow_version, matplotlib_version]\n",
    "\n",
    "with open(writepath, 'r') as file:\n",
    "    for line in file:\n",
    "        requirements.append(line.strip('\\n'))\n",
    "\n",
    "with open(writepath, 'a') as file:\n",
    "    for package in packages:\n",
    "        if package not in requirements:\n",
    "            file.write(package + '\\n')\n",
    "\n",
    "max_characters = len(python_version)\n",
    "for package in packages:\n",
    "    if max(max_characters, len(package)) > max_characters:\n",
    "        max_characters = max(max_characters, len(package))\n",
    "\n",
    "print('#' * (max_characters + 8))\n",
    "print('#' * 2 + ' ' * (max_characters + 4) + '#' * 2)\n",
    "print('#' * 2 + ' ' * 2 + python_version + ' ' *\n",
    "      (max_characters - len(python_version) + 2) + '#' * 2)\n",
    "for package in packages:\n",
    "    print('#' * 2 + ' ' * 2 + package + ' ' *\n",
    "          (max_characters - len(package) + 2) + '#' * 2)\n",
    "print('#' * 2 + ' ' * (max_characters + 4) + '#' * 2)\n",
    "print('#' * (max_characters + 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
