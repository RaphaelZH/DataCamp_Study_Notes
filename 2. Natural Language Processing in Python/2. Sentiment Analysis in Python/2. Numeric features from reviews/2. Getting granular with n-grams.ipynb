{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:20:21.989524Z",
     "start_time": "2020-07-24T11:20:12.960881Z"
    }
   },
   "source": [
    "```\n",
    "#############################################\n",
    "##                                         ##\n",
    "##  Natural Language Processing in Python  ##\n",
    "##                                         ##\n",
    "#############################################\n",
    "\n",
    "ยง2 Sentiment Analysis in Python\n",
    "\n",
    "ยง2.2 Numeric features from reviews\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting granular with n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are context matters?\n",
    "\n",
    "* Putting 'not' in front of a word (negation) is one example of how context matters.\n",
    "\n",
    "* E.g.,\n",
    "\n",
    "    > *I am happy, **not sad**.*\n",
    "    > \n",
    "    > *I am sad, **not happy**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the capturing context with a BOW?\n",
    "\n",
    "* **Unigrams**: single tokens.\n",
    "\n",
    "* **Bigrams**: pairs of tokens.\n",
    "\n",
    "* **Trigrams**: triples of tokens.\n",
    "\n",
    "* **N-grams**: a sequence of n-tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of n-grams with the `CountVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:15.030653Z",
     "start_time": "2021-02-09T04:27:12.040280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'the', 'today', 'weather', 'wonderful']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentence = ['The weather today is wonderful.']\n",
    "\n",
    "# Only unigrams\n",
    "vect_1 = CountVectorizer(ngram_range=(1, 1))\n",
    "vect_1.fit(sentence)\n",
    "X = vect_1.transform(sentence)\n",
    "vect_1.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:15.043594Z",
     "start_time": "2021-02-09T04:27:15.034598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'is wonderful',\n",
       " 'the',\n",
       " 'the weather',\n",
       " 'today',\n",
       " 'today is',\n",
       " 'weather',\n",
       " 'weather today',\n",
       " 'wonderful']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uni- and bigrams\n",
    "vect_1_2 = CountVectorizer(ngram_range=(1, 2))\n",
    "vect_1_2.fit(sentence)\n",
    "X = vect_1_2.transform(sentence)\n",
    "vect_1_2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:15.053689Z",
     "start_time": "2021-02-09T04:27:15.046457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is wonderful', 'the weather', 'today is', 'weather today']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only bigrams\n",
    "vect_2 = CountVectorizer(ngram_range=(2, 2))\n",
    "vect_2.fit(sentence)\n",
    "X = vect_2.transform(sentence)\n",
    "vect_2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:15.065134Z",
     "start_time": "2021-02-09T04:27:15.058892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the weather today', 'today is wonderful', 'weather today is']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only trigrams\n",
    "vect_3 = CountVectorizer(ngram_range=(3, 3))\n",
    "vect_3.fit(sentence)\n",
    "X = vect_3.transform(sentence)\n",
    "vect_3.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the best n?\n",
    "\n",
    "* A longer sequence of tokens:\n",
    "\n",
    "    * results in more features\n",
    "\n",
    "    * leads higher precision of machine learning models\n",
    "\n",
    "    * has a risk of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to specifying vocabulary size?\n",
    "\n",
    "* `CountVectorizer(max_features, max_df, min_df)`:\n",
    "\n",
    "    * **`max_features`**: if specified, it will include only the topmost frequent words in the vocabulary\n",
    "\n",
    "        * if `max_features = None`, all words will be included\n",
    "        \n",
    "    * **`max_df`**: ignore terms higher than the specified frequency\n",
    "        \n",
    "        * if it is set to an integer, then absolute count; if it is set to a float, then it is a proportion\n",
    "        \n",
    "        * default is `1`, which means it does not ignore any terms\n",
    "        \n",
    "    * **`min_df`**: ignore terms with lower than specified frequency\n",
    "    \n",
    "        * if it is set to an integer, then absolute count; if it is set to a float, then it is a proportion\n",
    "        \n",
    "        * default is `1`, which means it does not ignore any terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice exercises for getting granular with n-grams:\n",
    "\n",
    "$\\blacktriangleright$ **Package pre-loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:16.101391Z",
     "start_time": "2021-02-09T04:27:15.067853Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data pre-loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:16.213363Z",
     "start_time": "2021-02-09T04:27:16.104732Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_all = pd.read_csv('ref2. Amazon product reviews sample.csv')[[\n",
    "    'score', 'review'\n",
    "]]\n",
    "reviews = reviews_all[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **The token sequence with specific length BOW practice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:16.320081Z",
     "start_time": "2021-02-09T04:27:16.221067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10  10 95  10 cups  100  100 years  110  110 years  114622  \\\n",
      "0   0      0        0    0          0    0          0       0   \n",
      "1   0      0        0    0          0    0          0       0   \n",
      "2   0      0        0    0          0    0          0       0   \n",
      "3   0      0        0    0          0    0          0       0   \n",
      "4   0      0        0    0          0    0          0       0   \n",
      "\n",
      "   114622 excellent  12  ...  youtube video  yr  yr old  yucky  yucky thick  \\\n",
      "0                 0   0  ...              0   0       0      0            0   \n",
      "1                 0   0  ...              0   0       0      0            0   \n",
      "2                 0   0  ...              0   0       0      0            0   \n",
      "3                 0   0  ...              0   0       0      0            0   \n",
      "4                 0   0  ...              0   0       0      0            0   \n",
      "\n",
      "   zelbessdisk  zelbessdisk three  zen  zen baseball  zen motorcycle  \n",
      "0            0                  0    0             0               0  \n",
      "1            0                  0    0             0               0  \n",
      "2            0                  0    0             0               0  \n",
      "3            1                  1    0             0               0  \n",
      "4            0                  0    0             0               0  \n",
      "\n",
      "[5 rows x 8436 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build the vectorizer, specify token sequence and fit\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Data re-pre-loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:16.562572Z",
     "start_time": "2021-02-09T04:27:16.335634Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_all = pd.read_csv('ref3. IMDB movie reviews sample.csv')[[\n",
    "    'review', 'label'\n",
    "]]\n",
    "movies = movies_all[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **Movies reviews with the size of vocabulary practice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:17.110506Z",
     "start_time": "2021-02-09T04:27:16.593276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   about  all  also  an  and  any  are  as  at  bad  ...  well  were  what  \\\n",
      "0      0    0     0   0    1    0    0   2   0    0  ...     0     0     0   \n",
      "1      0    3     1   1   11    0    3   3   4    0  ...     0     0     1   \n",
      "2      0    0     0   1    7    0    1   2   1    0  ...     0     0     0   \n",
      "3      0    0     0   2    1    0    1   2   2    0  ...     1     0     0   \n",
      "4      0    3     0   0    8    0    3   1   0    0  ...     2     1     0   \n",
      "\n",
      "   when  which  who  will  with  would  you  \n",
      "0     0      0    0     0     1      1    0  \n",
      "1     1      2    0     2     7      2    3  \n",
      "2     0      0    0     0     2      0    0  \n",
      "3     0      0    1     0     0      0    1  \n",
      "4     1      1    0     0     2      0    0  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build the vectorizer, specify size of vocabulary and fit\n",
    "vect = CountVectorizer(max_features=100)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:17.791989Z",
     "start_time": "2021-02-09T04:27:17.118032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  000s  007  00s  01  06  07  08  10  ...  zombification  zombified  \\\n",
      "0   0    0     0    0    0   0   0   0   0   0  ...              0          1   \n",
      "1   0    0     0    0    0   0   0   0   0   1  ...              0          0   \n",
      "2   0    0     0    0    0   0   0   0   0   0  ...              0          0   \n",
      "3   0    0     0    0    0   0   0   0   0   0  ...              0          0   \n",
      "4   0    0     0    0    0   0   0   0   0   1  ...              0          0   \n",
      "\n",
      "   zone  zoo  zoom  zooms  zsigmond  zulu  zuniga  zvyagvatsev  \n",
      "0     0    0     0      0         0     0       0            0  \n",
      "1     0    0     0      0         0     0       0            0  \n",
      "2     0    0     0      0         0     0       0            0  \n",
      "3     0    0     0      0         0     0       0            0  \n",
      "4     0    0     0      0         0     0       0            0  \n",
      "\n",
      "[5 rows x 17669 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build and fit the vectorizer\n",
    "vect = CountVectorizer(max_df=200)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:18.148759Z",
     "start_time": "2021-02-09T04:27:17.796443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10  about  absolutely  acting  action  actor  actors  actually  after  \\\n",
      "0   0      0           0       0       0      0       0         0      0   \n",
      "1   1      0           0       1       0      0       1         0      0   \n",
      "2   0      0           0       0       0      0       0         0      1   \n",
      "3   0      0           0       0       1      0       0         0      0   \n",
      "4   1      0           0       0       1      0       0         0      0   \n",
      "\n",
      "   again  ...  wouldn  written  wrong  year  years  yes  yet  you  young  your  \n",
      "0      0  ...       0        0      0     0      0    0    0    0      0     0  \n",
      "1      0  ...       0        0      0     2      0    0    1    3      0     2  \n",
      "2      0  ...       0        0      0     0      0    0    0    0      1     0  \n",
      "3      0  ...       0        0      0     0      0    0    0    1      1     0  \n",
      "4      0  ...       0        0      1     0      0    0    0    0      0     0  \n",
      "\n",
      "[5 rows x 434 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build and fit the vectorizer\n",
    "vect = CountVectorizer(min_df=50)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ **BOW with n-grams and vocabulary size practice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:18.230255Z",
     "start_time": "2021-02-09T04:27:18.151422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1980 style  aa batteries  aaa batteries  able to  about the  about this  \\\n",
      "0           0             0              0        0          0           0   \n",
      "1           0             0              0        0          0           0   \n",
      "2           0             0              0        0          0           0   \n",
      "3           0             0              0        0          0           0   \n",
      "4           0             0              0        0          0           0   \n",
      "\n",
      "   across the  after that  again the  ahead of  ...  you know  you look  \\\n",
      "0           0           0          0         0  ...         0         0   \n",
      "1           0           0          0         0  ...         0         0   \n",
      "2           0           0          0         0  ...         0         0   \n",
      "3           0           0          0         0  ...         0         0   \n",
      "4           0           0          0         0  ...         1         0   \n",
      "\n",
      "   you need  you should  you ve  you want  you will  your imagination  \\\n",
      "0         0           0       0         0         0                 0   \n",
      "1         0           0       0         0         0                 0   \n",
      "2         0           0       2         0         0                 0   \n",
      "3         0           0       0         0         0                 0   \n",
      "4         0           0       1         0         0                 0   \n",
      "\n",
      "   your money  yr old  \n",
      "0           0       0  \n",
      "1           0       0  \n",
      "2           0       0  \n",
      "3           0       0  \n",
      "4           0       0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build the vectorizer, specify max features and fit\n",
    "vect = CountVectorizer(max_features=1000, ngram_range=(2, 2), max_df=500)\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create a DataFrame from the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:18.253014Z",
     "start_time": "2021-02-09T04:27:18.240083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python version is 3.7.9.\n",
      "The pandas version is 1.2.1.\n",
      "The scikit-learn version is 0.24.1.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "\n",
    "print('The Python version is {}.'.format(sys.version.split()[0]))\n",
    "print('The pandas version is {}.'.format(pd.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
